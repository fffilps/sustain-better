# -*- coding: utf-8 -*-
"""smart_garbage.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LCFSb6YCxaQU4UznwY6y242Ck-xtMJcz

# IMPORTING TENSORFLOW
"""

pip install tensorflow

"""# IMPORTING TENSORFLOW"""

import tensorflow as tf

"""# USING CPU

"""

from google.colab import drive

# Mount Google Drive
drive.mount('/content/drive')

device = "/device:CPU:0"

"""# DATA IMPORTING"""

import os
import matplotlib.pyplot as plt
from PIL import Image
import math

dir_example = "/content/drive/My Drive/Smart-Garbage-Segregation/Data"

classes = os.listdir(dir_example)
print(classes)

dir_example = "/content/drive/My Drive/Smart-Garbage-Segregation/visualize"

train_classes = os.listdir(dir_example)
print(train_classes)

"""# DATA VISUALIZATION"""

dir_with_examples = '/content/drive/My Drive/Smart-Garbage-Segregation/visualize'
files_per_row = 6
files_in_dir = os.listdir(dir_with_examples)
number_of_cols = files_per_row
number_of_rows = int(len(files_in_dir) / number_of_cols)

# Generate the subplots
fig, axs = plt.subplots(number_of_rows, number_of_cols)
fig.set_size_inches(20, 15, forward=True)

# Map each file to subplot
try:
  for i in range(0, len(files_in_dir)):
    file_name = files_in_dir[i]
    image = Image.open(f'{dir_with_examples}/{file_name}')
    row = math.floor(i / files_per_row)
    col = i % files_per_row
    axs[col].imshow(image)
    axs[col].axis('off')
except:
  pass
# Show the plot
plt.show()



from tensorflow.keras.models import Sequential
from keras.layers import Conv2D, Flatten, MaxPooling2D, Dense, Dropout, SpatialDropout2D
from tensorflow.keras.losses import sparse_categorical_crossentropy, binary_crossentropy
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator

"""# PREPARING OF DATA"""

train = '/content/drive/My Drive/Smart-Garbage-Segregation/Data/Train'
test = '/content/drive/My Drive/Smart-Garbage-Segregation/Data/Test'

train_generator = ImageDataGenerator(rescale = 1/255)

train_generator = train_generator.flow_from_directory(train,
                                                      target_size = (300,300),
                                                      batch_size = 32,
                                                      class_mode = 'sparse')

labels = (train_generator.class_indices)
print(labels,'\n')

labels = dict((v,k) for k,v in labels.items())
print(labels)

for image_batch, label_batch in train_generator:
  break
image_batch.shape, label_batch.shape

test_generator = ImageDataGenerator(rescale = 1./255)

test_generator = test_generator.flow_from_directory(test,
                                                    target_size = (300,300),
                                                    batch_size = 32,
                                                    class_mode = 'sparse')

test_labels = (test_generator.class_indices)
print(test_labels,'\n')

test_labels = dict((v,k) for k,v in test_labels.items())
print(test_labels)

"""# Importing oneDNN"""

# Commented out IPython magic to ensure Python compatibility.
# Check the current Python version
!python --version

!apt-get install -y build-essential cmake
!git clone --recursive https://github.com/oneapi-src/oneDNN.git
# %cd oneDNN
!git checkout <version>

# Create build directory and switch to it
!mkdir -p build
# %cd build

# Configure oneDNN build
!cmake ..

# Build oneDNN
!make -j$(nproc)











"""# LABELING"""

print(train_generator.class_indices)
Labels = '\n'.join(sorted(train_generator.class_indices.keys()))

with open('Labels.txt', 'w') as file:
  file.write(Labels)

"""# CREATING MODEL WITH oneDNN OPTIMIZATION"""

import os
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '1'

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout

model = Sequential()

# Convolution blocks
model.add(Conv2D(32, kernel_size=(3,3), padding='same', input_shape=(300,300,3), activation='relu'))
model.add(MaxPooling2D(pool_size=2))

model.add(Conv2D(64, kernel_size=(3,3), padding='same', activation='relu'))
model.add(MaxPooling2D(pool_size=2))

model.add(Conv2D(32, kernel_size=(3,3), padding='same', activation='relu'))
model.add(MaxPooling2D(pool_size=2))

# Classification layers
model.add(Flatten())

model.add(Dense(64, activation='relu'))
model.add(Dropout(0.2))
model.add(Dense(32, activation='relu'))

model.add(Dropout(0.2))
model.add(Dense(6, activation='softmax'))

"""# COMPILING MODEL  # Enable OneDNN optimizations"""

model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
model.summary()

"""# TRAINING THE MODEL(10 EPOCHS)"""

model.fit_generator(train_generator,
          epochs=10,
          steps_per_epoch=2184//32)

"""# TESTING PREDICTION"""

import keras.utils as ku
import numpy as np

test_img = '/content/drive/My Drive/Smart-Garbage-Segregation/Data/Test/paper/paper522.jpg'
img = ku.load_img(test_img, target_size = (300,300))
img = ku.img_to_array(img, dtype=np.uint8)
img = np.array(img)/255.0
prediction = model.predict(img[np.newaxis, ...])

#print("Predicted shape",p.shape)
print("Probability:",np.max(prediction[0], axis=-1))
predicted_class = labels[np.argmax(prediction[0], axis=-1)]
print("Classified:",predicted_class,'\n')

plt.axis('off')
plt.imshow(img.squeeze())
plt.title("Loaded Image")

classes = []
probability = []

for i,j in enumerate(prediction[0],0):
  print(labels[i].upper(),':',round(j*100,2),'%')

test_img = '/content/drive/My Drive/Smart-Garbage-Segregation/Data/Test/metal/metal386.jpg'
img = ku.load_img(test_img, target_size = (300,300))
img = ku.img_to_array(img, dtype=np.uint8)
img = np.array(img)/255.0
prediction = model.predict(img[np.newaxis, ...])

#print("Predicted shape",p.shape)
print("Probability:",np.max(prediction[0], axis=-1))
predicted_class = labels[np.argmax(prediction[0], axis=-1)]
print("Classified:",predicted_class,'\n')

plt.axis('off')
plt.imshow(img.squeeze())
plt.title("Loaded Image")

classes = []
probability = []

for i,j in enumerate(prediction[0],0):
  print(labels[i].upper(),':',round(j*100,2),'%')

test_img = '/content/drive/My Drive/Smart-Garbage-Segregation/Data/Test/plastic/plastic430.jpg'
img = ku.load_img(test_img, target_size = (300,300))
img = ku.img_to_array(img, dtype=np.uint8)
img = np.array(img)/255.0
prediction = model.predict(img[np.newaxis, ...])

#print("Predicted shape",p.shape)
print("Probability:",np.max(prediction[0], axis=-1))
predicted_class = labels[np.argmax(prediction[0], axis=-1)]
print("Classified:",predicted_class,'\n')

plt.axis('off')
plt.imshow(img.squeeze())
plt.title("Loaded Image")

classes = []
probability = []

for i,j in enumerate(prediction[0],0):
  print(labels[i].upper(),':',round(j*100,2),'%')

test_img = '/content/drive/My Drive/Smart-Garbage-Segregation/Data/Test/cardboard/cardboard355.jpg'
img = ku.load_img(test_img, target_size = (300,300))
img = ku.img_to_array(img, dtype=np.uint8)
img = np.array(img)/255.0
prediction = model.predict(img[np.newaxis, ...])

#print("Predicted shape",p.shape)
print("Probability:",np.max(prediction[0], axis=-1))
predicted_class = labels[np.argmax(prediction[0], axis=-1)]
print("Classified:",predicted_class,'\n')

plt.axis('off')
plt.imshow(img.squeeze())
plt.title("Loaded Image")

classes = []
probability = []

for i,j in enumerate(prediction[0],0):
  print(labels[i].upper(),':',round(j*100,2),'%')

"""# SAVING THE TRAINED MODEL"""

model.save('modelnew.h5')

import cv2
import numpy as np
import matplotlib.pyplot as plt

def detect_dominant_color(image_path):
    # Load the image
    image = cv2.imread(image_path)
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    # Convert the image to grayscale and apply edge detection
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    edges = cv2.Canny(gray, 50, 150)

    # Find contours in the edge map
    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    if len(contours) == 0:
        return None, 0

    # Get the largest contour (assuming the object is the largest contour)
    largest_contour = max(contours, key=cv2.contourArea)

    # Create a mask for the largest contour
    mask = np.zeros_like(gray)
    cv2.drawContours(mask, [largest_contour], -1, 255, thickness=cv2.FILLED)

    # Apply the mask to the image
    masked_image = cv2.bitwise_and(image_rgb, image_rgb, mask=mask)

    # Convert the masked image to the HSV color space
    hsv_image = cv2.cvtColor(masked_image, cv2.COLOR_RGB2HSV)

    # Define color ranges and create masks
    color_ranges = {
        'red': ((0, 70, 50), (10, 255, 255)),
        'green': ((36, 25, 25), (86, 255, 255)),
        'blue': ((94, 80, 2), (126, 255, 255)),
        'yellow': ((15, 150, 20), (35, 255, 255)),
        'black': ((0, 0, 0), (180, 255, 30)),
        'white': ((0, 0, 200), (180, 20, 255))
    }

    max_area = 0
    dominant_color = None

    for color, (lower, upper) in color_ranges.items():
        lower = np.array(lower, dtype="uint8")
        upper = np.array(upper, dtype="uint8")
        mask = cv2.inRange(hsv_image, lower, upper)
        area = cv2.countNonZero(mask)

        if area > max_area:
            max_area = area
            dominant_color = color

    return dominant_color, max_area

def display_image(image_path):
    # Load the image
    image = cv2.imread(image_path)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    plt.imshow(image)
    plt.axis('off')
    plt.show()


# Example usage
image_path = '/content/drive/My Drive/Smart-Garbage-Segregation/Data/Test/trash2.jpg'
color, area = detect_dominant_color(image_path)

print(f'Dominant color: {color} with area: {area}')
display_image(image_path)

